{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed5981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame reader finished.\n",
      "Frame processor finished.\n",
      "Exiting main display loop.\n",
      "Program finished.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "BUFFER_SIZE = 5  # Number of frames to buffer between producer and consumer\n",
    "DISPLAY_FPS = 30 # Target FPS for display. Setting this too high might cause stuttering.\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# Queues for inter-thread communication\n",
    "frame_queue = queue.Queue(maxsize=BUFFER_SIZE)\n",
    "processed_frame_queue = queue.Queue(maxsize=BUFFER_SIZE)\n",
    "\n",
    "# Event to signal when the video reading is done\n",
    "video_finished = threading.Event()\n",
    "processing_finished = threading.Event()\n",
    "\n",
    "# --- Producer Thread: Reads frames from video ---\n",
    "def frame_reader(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        video_finished.set()\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_queue.put(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    video_finished.set()\n",
    "    print(\"Frame reader finished.\")\n",
    "\n",
    "# --- Consumer Thread: Processes frames ---\n",
    "def frame_processor():\n",
    "    while True:\n",
    "        if video_finished.is_set() and frame_queue.empty():\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # This prevents the thread from blocking indefinitely if the producer is slow\n",
    "            # or has finished and there are no more frames.\n",
    "            frame = frame_queue.get(timeout=0.1) \n",
    "        except queue.Empty:\n",
    "            continue # No frame available, try again\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        boxes, weights = hog.detectMultiScale(frame_resized, winStride=(8,8), scale=1.02, padding=(4,4))\n",
    "\n",
    "        for i, (x,y,w,h) in enumerate(boxes):\n",
    "            if weights[i] < 0.13:\n",
    "                continue\n",
    "            #elif weights[i] < 0.3 and weights[i] > 0.13:\n",
    "            #    cv2.rectangle(frame_resized, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            #elif weights[i] < 0.7 and weights[i] > 0.3:\n",
    "            #    cv2.rectangle(frame_resized, (x, y), (x+w, y+h), (50, 122, 255), 2)\n",
    "            elif weights[i] > 0.7:\n",
    "                cv2.rectangle(frame_resized, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame_resized, 'High', (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        #cv2.putText(frame_resized, 'Moderate', (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 122, 255), 2)\n",
    "        #cv2.putText(frame_resized, 'Low', (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        processed_frame_queue.put(frame_resized)\n",
    "        frame_queue.task_done()\n",
    "    \n",
    "    processing_finished.set() # Signal that processing is complete\n",
    "    print(\"Frame processor finished.\")\n",
    "\n",
    "def main():\n",
    "    video_path = '../853889-hd_1920_1080_25fps.mp4'\n",
    "\n",
    "    # Start the producer thread\n",
    "    reader_thread = threading.Thread(target=frame_reader, args=(video_path,))\n",
    "    reader_thread.daemon = True # Allow the main program to exit even if this thread is running\n",
    "    reader_thread.start()\n",
    "\n",
    "    # Start the consumer thread\n",
    "    processor_thread = threading.Thread(target=frame_processor)\n",
    "    processor_thread.daemon = True\n",
    "    processor_thread.start()\n",
    "\n",
    "    last_display_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        if video_finished.is_set() and processing_finished.is_set() and processed_frame_queue.empty():\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Get processed frame for display\n",
    "            frame_to_display = processed_frame_queue.get(timeout=0.1) \n",
    "        except queue.Empty:\n",
    "            # If the queue is empty, wait a bit before trying again to avoid busy-waiting\n",
    "            time.sleep(0.01) \n",
    "            continue\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame_to_display)\n",
    "        processed_frame_queue.task_done() # Indicate that a task from processed_frame_queue is done\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27: # ESC key to exit\n",
    "            break\n",
    "\n",
    "    print(\"Exiting main display loop.\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Program finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f82d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads started. Press 'ESC' to exit.\n",
      "Main loop ending, waiting for threads to finish...\n",
      "Frame processor thread stopped.\n",
      "Frame capturer thread stopped.\n",
      "All threads finished.\n",
      "Application closed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "# https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker\n",
    "\n",
    "# --- High-Five Detection Logic (from previous response) ---\n",
    "def is_all_fingers_up(hand_landmarks):\n",
    "    \"\"\"\n",
    "    Checks if all fingers (thumb, index, middle, ring, pinky) are extended upwards\n",
    "    in a high-five pose.\n",
    "\n",
    "    Args:\n",
    "        hand_landmarks: A MediaPipe HandLandmark object containing the 3D coordinates\n",
    "                        of the hand landmarks.\n",
    "\n",
    "    Returns:\n",
    "        True if all fingers are detected as up, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if not hand_landmarks:\n",
    "        return False\n",
    "\n",
    "    fingers = {\n",
    "        'thumb': [mp_hands.HandLandmark.THUMB_CMC, mp_hands.HandLandmark.THUMB_MCP, mp_hands.HandLandmark.THUMB_IP, mp_hands.HandLandmark.THUMB_TIP],\n",
    "        'index': [mp_hands.HandLandmark.INDEX_FINGER_MCP, mp_hands.HandLandmark.INDEX_FINGER_PIP, mp_hands.HandLandmark.INDEX_FINGER_DIP, mp_hands.HandLandmark.INDEX_FINGER_TIP],\n",
    "        'middle': [mp_hands.HandLandmark.MIDDLE_FINGER_MCP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP, mp_hands.HandLandmark.MIDDLE_FINGER_DIP, mp_hands.HandLandmark.MIDDLE_FINGER_TIP],\n",
    "        'ring': [mp_hands.HandLandmark.RING_FINGER_MCP, mp_hands.HandLandmark.RING_FINGER_PIP, mp_hands.HandLandmark.RING_FINGER_DIP, mp_hands.HandLandmark.RING_FINGER_TIP],\n",
    "        'pinky': [mp_hands.HandLandmark.PINKY_MCP, mp_hands.HandLandmark.PINKY_PIP, mp_hands.HandLandmark.PINKY_DIP, mp_hands.HandLandmark.PINKY_TIP],\n",
    "    }\n",
    "\n",
    "    angle_threshold = 30  # degrees - fine-tune this as needed\n",
    "\n",
    "    all_fingers_extended = True\n",
    "    wrist_y = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y\n",
    "\n",
    "    for finger_name, landmarks in fingers.items():\n",
    "        if finger_name == 'thumb':\n",
    "            mcp = hand_landmarks.landmark[landmarks[1]]\n",
    "            ip = hand_landmarks.landmark[landmarks[2]]\n",
    "            tip = hand_landmarks.landmark[landmarks[3]]\n",
    "\n",
    "            if tip.y > mcp.y + (wrist_y - mcp.y) * 0.2:\n",
    "                all_fingers_extended = False\n",
    "                break\n",
    "\n",
    "            vec_mcp_ip = np.array([ip.x - mcp.x, ip.y - mcp.y])\n",
    "            vec_ip_tip = np.array([tip.x - ip.x, tip.y - ip.y])\n",
    "\n",
    "            dot_product = np.dot(vec_mcp_ip, vec_ip_tip)\n",
    "            magnitude_mcp_ip = np.linalg.norm(vec_mcp_ip)\n",
    "            magnitude_ip_tip = np.linalg.norm(vec_ip_tip)\n",
    "\n",
    "            if magnitude_mcp_ip == 0 or magnitude_ip_tip == 0:\n",
    "                continue\n",
    "\n",
    "            angle_rad = np.arccos(dot_product / (magnitude_mcp_ip * magnitude_ip_tip))\n",
    "            angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "            if angle_deg > 160:\n",
    "                 all_fingers_extended = False\n",
    "                 break\n",
    "        else:\n",
    "            mcp = hand_landmarks.landmark[landmarks[0]]\n",
    "            pip = hand_landmarks.landmark[landmarks[1]]\n",
    "            dip = hand_landmarks.landmark[landmarks[2]]\n",
    "            tip = hand_landmarks.landmark[landmarks[3]]\n",
    "\n",
    "            if tip.y > pip.y or pip.y > mcp.y:\n",
    "                all_fingers_extended = False\n",
    "                break\n",
    "\n",
    "            vec_mcp_pip = np.array([pip.x - mcp.x, pip.y - mcp.y, pip.z - mcp.z])\n",
    "            vec_pip_dip = np.array([dip.x - pip.x, dip.y - pip.y, dip.z - pip.z])\n",
    "            angle_pip = np.degrees(np.arccos(np.dot(vec_mcp_pip, vec_pip_dip) / (np.linalg.norm(vec_mcp_pip) * np.linalg.norm(vec_pip_dip) + 1e-6)))\n",
    "\n",
    "            vec_pip_dip_2 = np.array([dip.x - pip.x, dip.y - pip.y, dip.z - pip.z])\n",
    "            vec_dip_tip = np.array([tip.x - dip.x, tip.y - dip.y, tip.z - dip.z])\n",
    "            angle_dip = np.degrees(np.arccos(np.dot(vec_pip_dip_2, vec_dip_tip) / (np.linalg.norm(vec_pip_dip_2) * np.linalg.norm(vec_dip_tip) + 1e-6)))\n",
    "\n",
    "            if angle_pip > angle_threshold or angle_dip > angle_threshold:\n",
    "                all_fingers_extended = False\n",
    "                break\n",
    "\n",
    "    return all_fingers_extended\n",
    "\n",
    "# --- Global Flags and Queues ---\n",
    "cap_queue = queue.Queue(maxsize=10) # Queue for raw frames from camera\n",
    "processed_queue = queue.Queue(maxsize=10) # Queue for processed frames to display\n",
    "running = True\n",
    "\n",
    "# --- MediaPipe Initialization ---\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# --- Thread Functions ---\n",
    "\n",
    "def frame_capturer(cap, frame_queue, running_flag):\n",
    "    \"\"\"\n",
    "    Thread function to capture frames from the camera.\n",
    "    \"\"\"\n",
    "    while running_flag.is_set():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame from capturer.\")\n",
    "            time.sleep(0.01) # Avoid busy-waiting\n",
    "            continue\n",
    "        try:\n",
    "            frame_queue.put(frame, block=False) # Use non-blocking put\n",
    "        except queue.Full:\n",
    "            # Optionally, drop the oldest frame if the queue is full to prioritize fresh frames\n",
    "            # print(\"Frame capture queue full, dropping frame.\")\n",
    "            pass\n",
    "    print(\"Frame capturer thread stopped.\")\n",
    "\n",
    "def frame_processor(input_queue, output_queue, running_flag):\n",
    "    \"\"\"\n",
    "    Thread function to process frames using MediaPipe.\n",
    "    \"\"\"\n",
    "    with mp_hands.Hands(\n",
    "        min_detection_confidence=0.7,\n",
    "        min_tracking_confidence=0.5,\n",
    "        max_num_hands=1) as hands:\n",
    "        while running_flag.is_set():\n",
    "            try:\n",
    "                image = input_queue.get(timeout=0.1) # Get with a timeout to allow graceful exit\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "            # Flip the image horizontally for a natural selfie-view display.\n",
    "            image = cv2.flip(image, 1)\n",
    "\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(image)\n",
    "\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            high_five_detected = False\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                        mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                    if is_all_fingers_up(hand_landmarks):\n",
    "                        high_five_detected = True\n",
    "                        break\n",
    "\n",
    "            try:\n",
    "                output_queue.put((image, high_five_detected), block=False)\n",
    "            except queue.Full:\n",
    "                # print(\"Processed frame queue full, dropping frame.\")\n",
    "                pass\n",
    "    print(\"Frame processor thread stopped.\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        exit()\n",
    "\n",
    "    # Use a threading.Event to signal threads to stop\n",
    "    running_event = threading.Event()\n",
    "    running_event.set() # Set the event to true initially\n",
    "\n",
    "    # Start the threads\n",
    "    capturer_thread = threading.Thread(target=frame_capturer, args=(cap, cap_queue, running_event))\n",
    "    processor_thread = threading.Thread(target=frame_processor, args=(cap_queue, processed_queue, running_event))\n",
    "\n",
    "    capturer_thread.start()\n",
    "    processor_thread.start()\n",
    "\n",
    "    print(\"Threads started. Press 'ESC' to exit.\")\n",
    "\n",
    "    while running_event.is_set():\n",
    "        try:\n",
    "            # Get the latest processed frame for display\n",
    "            display_image, high_five_status = processed_queue.get(timeout=0.05)\n",
    "            \n",
    "            if high_five_status:\n",
    "                cv2.putText(display_image, \"HIGH FIVE!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(display_image, \"No High Five\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow('MediaPipe Hands - High Five Detector (Multithreaded)', display_image)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                running_event.clear() # Signal threads to stop\n",
    "                break\n",
    "        except queue.Empty:\n",
    "            # No frame available for display yet, continue loop\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in main loop: {e}\")\n",
    "            running_event.clear()\n",
    "            break\n",
    "\n",
    "    print(\"Main loop ending, waiting for threads to finish...\")\n",
    "    capturer_thread.join()\n",
    "    processor_thread.join()\n",
    "    print(\"All threads finished.\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Application closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae9f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "con_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
